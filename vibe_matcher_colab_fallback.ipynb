{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a861f01",
   "metadata": {},
   "source": [
    "# Vibe Matcher — Mini Recommendation Notebook (with local fallback)\n",
    "\n",
    "This notebook is identical to the original but adds a local fallback using sentence-transformers if you don't have an OpenAI API key.\n",
    "\n",
    "How it works:\n",
    "- If `OPENAI_API_KEY` is set, the notebook uses OpenAI's `text-embedding-ada-002` to create embeddings.\n",
    "- If no key is present (or OpenAI calls fail), it falls back to a local SentenceTransformers model (`all-MiniLM-L6-v2`).\n",
    "- This keeps the demo runnable offline at the cost of slightly different embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb554084",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet openai pandas scikit-learn numpy sentence-transformers\n",
    "print('Installed/available packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8b7981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import openai\n",
    "\n",
    "if not os.getenv('OPENAI_API_KEY'):\n",
    "    try:\n",
    "        key = getpass('Enter your OpenAI API key (or leave blank to use local fallback): ')\n",
    "        if key:\n",
    "            os.environ['OPENAI_API_KEY'] = key\n",
    "    except Exception:\n",
    "        pass\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "print('OpenAI key set:', bool(openai.api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafd8bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = [\n",
    "    {'name': 'Boho Dress', 'desc': 'Flowy, earthy tones with embroidery — festival-ready, laid-back bohemian vibe.', 'tags': ['boho','flowy','festival','earthy']},\n",
    "    {'name': 'Urban Bomber', 'desc': 'Sleek bomber jacket in matte black — energetic, urban chic, great for nights out.', 'tags': ['urban','chic','energetic','edgy']},\n",
    "    {'name': 'Cozy Knit Sweater', 'desc': 'Chunky knit, soft neutrals — comfortable, cozy, perfect for relaxed days.', 'tags': ['cozy','casual','warm']},\n",
    "    {'name': 'Minimal Blazer', 'desc': 'Crisp lines and neutral tones for minimalist workwear — clean and refined.', 'tags': ['minimal','workwear','refined']},\n",
    "    {'name': 'Sport Luxe Jogger', 'desc': 'Athletic silhouette with luxe fabric — casual but energetic streetwear.', 'tags': ['sporty','streetwear','energetic']},\n",
    "    {'name': 'Retro Floral Blouse', 'desc': 'Vintage-inspired floral print — romantic, colorful, a playful retro feel.', 'tags': ['retro','floral','romantic']},\n",
    "    {'name': 'Tailored Trousers', 'desc': 'Tailored, high-waist trousers for polished and confident city looks.', 'tags': ['polished','city','confident']},\n",
    "]\n",
    "df = pd.DataFrame(products)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222bd79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding helper with OpenAI + local fallback\n",
    "_local_embed_model = None\n",
    "\n",
    "def get_local_embedding(text):\n",
    "    global _local_embed_model\n",
    "    if _local_embed_model is None:\n",
    "        try:\n",
    "            from sentence_transformers import SentenceTransformer\n",
    "        except Exception as e:\n",
    "            raise RuntimeError('sentence-transformers is required for local fallback. Install it with pip.')\n",
    "        _local_embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    emb = _local_embed_model.encode(text, convert_to_numpy=True)\n",
    "    return np.array(emb, dtype=float)\n",
    "\n",
    "def get_embedding(text, model='text-embedding-ada-002'):\n",
    "    if openai.api_key:\n",
    "        try:\n",
    "            resp = openai.Embedding.create(model=model, input=text)\n",
    "            emb = resp['data'][0]['embedding']\n",
    "            return np.array(emb, dtype=float)\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                resp = openai.embeddings.create(model=model, input=text)\n",
    "                emb = resp['data'][0]['embedding']\n",
    "                return np.array(emb, dtype=float)\n",
    "            except Exception as e2:\n",
    "                print('OpenAI embedding failed — falling back to local model:', e2)\n",
    "                return get_local_embedding(text)\n",
    "    else:\n",
    "        return get_local_embedding(text)\n",
    "\n",
    "print('Embedding helper ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36274429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for each product description and store in DataFrame\n",
    "embeddings = []\n",
    "start = time.perf_counter()\n",
    "for desc in df['desc']:\n",
    "    emb = get_embedding(desc)\n",
    "    embeddings.append(emb)\n",
    "end = time.perf_counter()\n",
    "df['embedding'] = embeddings\n",
    "print(f'Generated {len(embeddings)} embeddings in {end - start:.2f} seconds')\n",
    "display_df = df.copy()\n",
    "display_df['embedding'] = display_df['embedding'].apply(lambda v: v[:5].tolist())\n",
    "display_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6621660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "def match_query(query, top_k=3, model='text-embedding-ada-002', timeit_runs=3):\n",
    "    def embed_once():\n",
    "        get_embedding(query, model=model)\n",
    "    try:\n",
    "        times = timeit.repeat(stmt='embed_once()', globals=globals(), repeat=timeit_runs, number=1)\n",
    "        latency_avg = float(sum(times) / len(times))\n",
    "    except Exception:\n",
    "        t0 = time.perf_counter()\n",
    "        get_embedding(query, model=model)\n",
    "        t1 = time.perf_counter()\n",
    "        times = [t1 - t0]\n",
    "        latency_avg = times[0]\n",
    "\n",
    "    q_emb = get_embedding(query, model=model)\n",
    "    prod_embs = np.vstack(df['embedding'].values)\n",
    "    sims = cosine_similarity(q_emb.reshape(1, -1), prod_embs)[0]\n",
    "    top_idx = sims.argsort()[::-1][:top_k]\n",
    "    results = []\n",
    "    for idx in top_idx:\n",
    "        results.append({'name': df.iloc[idx]['name'], 'desc': df.iloc[idx]['desc'], 'tags': df.iloc[idx]['tags'], 'score': float(sims[idx])})\n",
    "    return {'query': query, 'latency_avg_s': latency_avg, 'latency_samples_s': times, 'results': results}\n",
    "\n",
    "print('Matching function ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b4e20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_queries = ['energetic urban chic','cozy boho festival','minimalist workwear']\n",
    "total_high_confidence = 0\n",
    "per_query_counts = []\n",
    "latencies = []\n",
    "for q in sample_queries:\n",
    "    out = match_query(q, top_k=3, timeit_runs=5)\n",
    "    latencies.append(out['latency_avg_s'])\n",
    "    count_high = sum(1 for r in out['results'] if r['score'] > 0.7)\n",
    "    per_query_counts.append({'query': q, 'count_gt_0_7': count_high})\n",
    "    total_high_confidence += count_high\n",
    "    print('\\nQuery:', out['query'])\n",
    "    print(f\"Embedding latency (avg): {out['latency_avg_s']*1000:.1f} ms\")\n",
    "    print('Latency samples (ms):', [f\"{s*1000:.1f}\" for s in out['latency_samples_s']])\n",
    "    print('Top results:')\n",
    "    for r in out['results']:\n",
    "        print(f\" - {r['name']} (score={r['score']:.4f}) | tags={r['tags']}\")\n",
    "    print(f\"Matches > 0.7 for this query: {count_high}\")\n",
    "\n",
    "print('\\nSummary:')\n",
    "print(f'Ran {len(sample_queries)} queries.')\n",
    "print('Per-query counts > 0.7:')\n",
    "for p in per_query_counts:\n",
    "    print(f\" - {p['query']}: {p['count_gt_0_7']}\")\n",
    "print(f'Overall total top-3 matches with similarity > 0.7: {total_high_confidence}')\n",
    "print('Latencies (ms, per-query average):', [f\"{l*1000:.1f}\" for l in latencies])\n",
    "print(f'Average latency across queries: {np.mean(latencies)*1000:.1f} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2640a090",
   "metadata": {},
   "source": [
    "## Reflection & Improvements\n",
    "- Use a dedicated vector DB (Pinecone, Weaviate) for scale.\n",
    "- Increase dataset size and collect user feedback for offline evaluation.\n",
    "- Cache embeddings to disk to avoid repeated API calls.\n",
    "- Try newer/larger embedding models for better semantic alignment."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
