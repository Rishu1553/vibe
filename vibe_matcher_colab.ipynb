{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6c503fb",
   "metadata": {},
   "source": [
    "# Vibe Matcher â€” Mini Recommendation Notebook\n",
    "\n",
    "This Colab notebook demonstrates a small \"Vibe Matcher\" that:\n",
    "\n",
    "- Creates a mock fashion product dataset (name, desc, tags)\n",
    "# Run 3 sample queries, print top-3 matches, similarity scores, latency via timeit, and count > 0.7 (per-query + overall)\n",
    "sample_queries = [\n",
    "    'energetic urban chic',\n",
    "    'cozy boho festival',\n",
    "    'minimalist workwear'\n",
    "]\n",
    "\n",
    "total_high_confidence = 0\n",
    "per_query_counts = []\n",
    "latencies = []\n",
    "\n",
    "for q in sample_queries:\n",
    "    out = match_query(q, top_k=3, timeit_runs=5)\n",
    "    # record average latency and samples\n",
    "    latencies.append(out['latency_avg_s'])\n",
    "\n",
    "    # count how many of the top-3 exceed 0.7 for this query\n",
    "    count_high = sum(1 for r in out['results'] if r['score'] > 0.7)\n",
    "    per_query_counts.append({'query': q, 'count_gt_0_7': count_high})\n",
    "    total_high_confidence += count_high\n",
    "\n",
    "    # Print results per query\n",
    "    print('\\nQuery:', out['query'])\n",
    "    print(f\"Embedding latency (avg over samples): {out['latency_avg_s']*1000:.1f} ms\")\n",
    "    print(f\"Latency samples (ms): {[f\"{s*1000:.1f}\" for s in out['latency_samples_s']]}\n",
    ","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa92e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae1ad21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f711db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e32f0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d472f425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f56d033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b85e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e6fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a302872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599f3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c18af28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4943e92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ad41cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0140eb41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daedb0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cbe9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7677d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5d425b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
