{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aefe3429",
   "metadata": {},
   "source": [
    "# Vibe Matcher — Mini Recommendation System\n",
    "\n",
    "This notebook demonstrates a small AI-powered recommender that maps a short vibe query (e.g. `energetic urban chic`) to the top-3 matching fashion products using OpenAI embeddings and cosine similarity.\n",
    "\n",
    "Instructions:\n",
    "- Provide an `OPENAI_API_KEY` via a `.env` file in the notebook environment or paste it when prompted.\n",
    "- Run cells top-to-bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1499563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once in Colab or Jupyter)\n",
    "%pip install --quiet openai pandas numpy scikit-learn python-dotenv\n",
    "\n",
    "print('Installed: openai, pandas, numpy, scikit-learn, python-dotenv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a253af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and environment setup\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from getpass import getpass\n",
    "import time\n",
    "import timeit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import openai\n",
    "\n",
    "# Load .env (if present) and set OpenAI API key from environment\n",
    "load_dotenv()\n",
    "if not os.getenv('OPENAI_API_KEY'):\n",
    "    try:\n",
    "        # interactive prompt (works in Colab/Jupyter)\n",
    "        key = getpass('Enter your OpenAI API key (or leave blank to stop): ')\n",
    "        if key:\n",
    "            os.environ['OPENAI_API_KEY'] = key\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Initialize OpenAI with the key from environment\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "print('OPENAI_API_KEY present:', bool(openai.api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50fd648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation: mock fashion products\n",
    "products = [\n",
    "    {\n",
    "        'name': 'Boho Dress',\n",
    "        'desc': 'Flowy maxi dress in earthy tones with embroidered details — festival-ready bohemian vibes.',\n",
    "        'tags': ['boho', 'flowy', 'festival']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Urban Bomber',\n",
    "        'desc': 'Matte black bomber jacket with structured shoulders — energetic and urban chic for nights out.',\n",
    "        'tags': ['urban', 'chic', 'edgy']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Cozy Knit Sweater',\n",
    "        'desc': 'Oversized chunky knit sweater in soft neutrals — warm, relaxed, and cozy.',\n",
    "        'tags': ['cozy', 'casual', 'warm']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Minimal Blazer',\n",
    "        'desc': 'Tailored single-breasted blazer in a minimalist palette — clean, polished workwear.',\n",
    "        'tags': ['minimal', 'workwear', 'polished']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Sport Luxe Jogger',\n",
    "        'desc': 'Sleek joggers with luxe fabric and tapered fit — sporty yet streetwise and energetic.',\n",
    "        'tags': ['sporty', 'streetwear', 'energetic']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Retro Floral Blouse',\n",
    "        'desc': 'Romantic floral blouse with puff sleeves — colorful, vintage-inspired style.',\n",
    "        'tags': ['retro', 'floral', 'romantic']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Tailored Trousers',\n",
    "        'desc': 'High-waisted tailored trousers for confident city looks — polished and structured.',\n",
    "        'tags': ['polished', 'city', 'confident']\n",
    "    }\n",
    "]\n",
    "df = pd.DataFrame(products)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52362cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: get embedding using OpenAI embeddings API (text-embedding-ada-002)\n",
    "def get_embedding(text, model='text-embedding-ada-002'):\n",
    "    \"Return a numpy array embedding for the given text using OpenAI.\n",
    "    Raises a RuntimeError if the API call fails or key is missing.\n",
    "    \"\"\"\n",
    "    if not openai.api_key:\n",
    "        raise RuntimeError('OPENAI_API_KEY not set. Please provide an API key in .env or via the prompt.')\n",
    "    try:\n",
    "        resp = openai.Embedding.create(model=model, input=text)\n",
    "        emb = resp['data'][0]['embedding']\n",
    "        return np.array(emb, dtype=float)\n",
    "    except Exception as e:\n",
    "        # try alternate client attribute (compatibility across client versions)\n",
    "        try:\n",
    "            resp = openai.embeddings.create(model=model, input=text)\n",
    "            emb = resp['data'][0]['embedding']\n",
    "            return np.array(emb, dtype=float)\n",
    "        except Exception as e2:\n",
    "            raise RuntimeError('Embedding request failed: ' + str(e2))\n",
    "\n",
    "# Generate embeddings for each product description and store in DataFrame\n",
    "embeddings = []\n",
    "start_all = time.perf_counter()\n",
    "for desc in df['desc']:\n",
    "    emb = get_embedding(desc)\n",
    "    embeddings.append(emb)\n",
    "end_all = time.perf_counter()\n",
    "df['embedding'] = embeddings\n",
    "print(f'Generated {len(embeddings)} embeddings in {end_all - start_all:.2f} seconds')\n",
    "\n",
    "# Show the dataframe with truncated embeddings for readability\n",
    "display_df = df.copy()\n",
    "display_df['embedding'] = display_df['embedding'].apply(lambda v: v[:5].tolist())\n",
    "display_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffd48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching logic: embed query, compute cosine similarity, return top-k results and timing info\n",
    "def match_query(query, top_k=3, model='text-embedding-ada-002', timeit_runs=3):\n",
    "    \"\"\"Return top-k matches for the query along with latency samples and average (seconds).\n",
    "    Uses timeit.repeat to measure embedding latency (number=1, repeat=timeit_runs).\n",
    "    \"\"\"\n",
    "    # wrapper to call get_embedding once for timeit\n",
    "    def embed_once():\n",
    "        get_embedding(query, model=model)\n",
    "\n",
    "    try:\n",
    "        samples = timeit.repeat(stmt='embed_once()', globals=globals(), repeat=timeit_runs, number=1)\n",
    "        latency_avg = float(sum(samples)/len(samples))\n",
    "    except Exception as e:\n",
    "        # Fallback single-run timing if timeit fails\n",
    "        t0 = time.perf_counter()\n",
    "        get_embedding(query, model=model)\n",
    "        t1 = time.perf_counter()\n",
    "        samples = [t1 - t0]\n",
    "        latency_avg = samples[0]\n",
    "\n",
    "    # Obtain the actual embedding to compute similarities\n",
    "    q_emb = get_embedding(query, model=model)\n",
    "    prod_embs = np.vstack(df['embedding'].values)\n",
    "    sims = cosine_similarity(q_emb.reshape(1, -1), prod_embs)[0]\n",
    "\n",
    "    # Collect top-k matches\n",
    "    top_idx = sims.argsort()[::-1][:top_k]\n",
    "    results = []\n",
    "    for idx in top_idx:\n",
    "        results.append({\n",
    "            'name': df.iloc[idx]['name'],\n",
    "            'desc': df.iloc[idx]['desc'],\n",
    "            'tags': df.iloc[idx]['tags'],\n",
    "            'score': float(sims[idx])\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        'query': query,\n",
    "        'latency_avg_s': latency_avg,\n",
    "        'latency_samples_s': samples,\n",
    "        'results': results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da141a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation: run sample queries and print formatted results, counts > 0.7, and latency\n",
    "sample_queries = ['energetic urban chic', 'cozy boho festival', 'minimalist workwear']\n",
    "overall_high = 0\n",
    "latencies = []\n",
    "print('Running sample queries...')\n",
    "for q in sample_queries:\n",
    "    out = match_query(q, top_k=3, timeit_runs=3)\n",
    "    latencies.append(out['latency_avg_s'])\n",
    "    print('\n",
    "Query:', out['query'])\n",
    "    print(f\"Latency (avg over samples): {out['latency_avg_s']*1000:.1f} ms\")\n",
    "    print('Top-3 matches:')\n",
    "    for r in out['results']:\n",
    "        print(f\" - {r['name']} (score={r['score']:.4f})\n",
    "     desc: {r['desc']}\n",
    "     tags: {r['tags']}\")\n",
    "    # count matches above threshold\n",
    "    count_high = sum(1 for r in out['results'] if r['score'] > 0.7)\n",
    "    overall_high += count_high\n",
    "    print(f\"Matches with similarity > 0.7: {count_high}\")\n",
    "\n",
    "# Summary metrics\n",
    "print('\n",
    "Summary:')\n",
    "print(f'Queries run: {len(sample_queries)}')\n",
    "print(f'Total top-3 matches with similarity > 0.7 (aggregated): {overall_high}')\n",
    "print('Per-query average latencies (ms):', [f\"{l*1000:.1f}\" for l in latencies])\n",
    "print(f'Average latency across queries: {np.mean(latencies)*1000:.1f} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0718bb10",
   "metadata": {},
   "source": [
    "## Reflection & Improvements\n",
    "\n",
    "- Accuracy: With a small mock catalog, embeddings capture broad semantic similarity but may confuse closely related styles. More descriptive product texts and tags improve precision.\n",
    "- Latency: Embedding latency depends on network and model; `text-embedding-ada-002` is reasonably fast but each query requires an API call. Use batching or local models for lower latency.\n",
    "- Improvements: Persist embeddings (Parquet) or use a vector DB (Pinecone, FAISS) for large catalogs; expand the dataset; experiment with larger embedding models; add user feedback loop for personalization."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
